Import Libraries

import pandas as pd

import numpy as np

import seaborn as sns

import matplotlib.pyplot as plt

 

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression

from sklearn.ensemble import RandomForestRegressor

from xgboost import XGBRegressor

from sklearn.impute import SimpleImputer

from sklearn.preprocessing import StandardScaler, OneHotEncoder

from sklearn.pipeline import Pipeline

from sklearn.compose import ColumnTransformer

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

 

# Load Dataset (Input)

# Replace this with your actual file path

data = pd.read_csv("AmesHousing.csv")

 

#  Drop missing target values

data = data.dropna(subset=["SalePrice"])

 

# �� Target and Features

X = data.drop("SalePrice", axis=1)

y = data["SalePrice"]

 

# Identify column types

num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

cat_features = X.select_dtypes(include=['object']).columns.tolist()

 

#  Build Preprocessing Pipelines

numeric_pipeline = Pipeline(steps=[

    ("imputer", SimpleImputer(strategy="mean")),

    ("scaler", StandardScaler())

])

 

categorical_pipeline = Pipeline(steps=[

    ("imputer", SimpleImputer(strategy="most_frequent")),

    ("encoder", OneHotEncoder(handle_unknown="ignore"))

])

 

preprocessor = ColumnTransformer(transformers=[

    ("num", numeric_pipeline, num_features),

    ("cat", categorical_pipeline, cat_features)

])

 

# �� Define Regression Models

models = {

    "Linear Regression": LinearRegression(),

    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),

    "XGBoost": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbosity=0)

}

 

#  Split Data

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

 

# Train and Evaluate Models

best_model = None

best_score = -np.inf

 

for name, model in models.items():

    pipeline = Pipeline(steps=[

        ("preprocessor", preprocessor),

        ("model", model)

    ])

    

    pipeline.fit(X_train, y_train)

    y_pred = pipeline.predict(X_test)

    

    mae = mean_absolute_error(y_test, y_pred)

    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    r2 = r2_score(y_test, y_pred)

 

    print(f"\n�� {name} Performance:")

    print(f"MAE  = {mae:.2f}")

    print(f"RMSE = {rmse:.2f}")

    print(f"R²   = {r2:.4f}")

 

    if r2 > best_score:

        best_score = r2

        best_model = pipeline

        best_preds = y_pred

 

# Save Predictions (Output)

output_df = pd.DataFrame({

    "ActualPrice": y_test.values,

    "PredictedPrice": best_preds

})

output_df.to_csv("predicted_house_prices.csv", index=False)

 

print("\n✅ Predictions saved to 'predicted_house_prices.csv'")

 

#  Visualize Results

plt.figure(figsize=(8, 6))

sns.scatterplot(x=y_test, y=best_preds)

plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')

plt.title("Actual vs Predicted House Prices")

plt.xlabel("Actual Prices")

plt.ylabel("Predicted Prices")

plt.grid(True)

plt.tight_layout()

plt.show()
